---
layout: papers
title: "NeuralGuide â€“ Bridging multimodal intelligence and wearable accessibility with on-device LLMs."
date: 2024-9-10
image: /images/neuralguide.png
authors: "<strong>Yilong Li</strong>, Shuai Zhang, Suman Banerjee"
desp: >
   A wearable earpiece device with camera and IMU sensor powered by our TinyLLM hardware platform performs fully on-device, multimodal inference without requiring internet connectivity. Equipped with an integrated camera, the device runs a visual instruction model (LlaVa-Onevision) to assist visually impaired individuals or elderly users in locating objects or navigating environments, such as identifying road signs or nearby landmarks. By leveraging a software-hardware co-design, the system ensures real-time, local natural language interaction. Current challenges include enhancing the device's positioning and reasoning capabilities to improve accuracy and reliability, addressing limitations in object localization and context understanding.
---

